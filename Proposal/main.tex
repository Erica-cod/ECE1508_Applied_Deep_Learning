\documentclass[11pt,a4paper,BCOR12mm, headexclude, footexclude, openright]{scrartcl} 
\usepackage{newpxtext}
\usepackage[british]{babel}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage[T1]{fontenc}
\usepackage{href-ul}
%\usepackage[scaled=0.85]{beramono}            % load a nice TT font
%\lstset{basicstyle=\ttfamily, language=sh}  
\lstset{columns=fullflexible,basicstyle=\ttfamily}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{ifthen}
\usepackage{amsmath,amsfonts,amsthm}
%\usepackage{sfmath}
%\usepackage{eulervm}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{sectsty}
\usepackage{bbm}
\usepackage{commands}
\usepackage{tikz,pgfplots}
\usepackage{tikz-cd}
\usetikzlibrary{patterns,intersections,matrix,fit,trees,positioning,chains,shapes.geometric,shapes,angles,quotes,pgfplots.fillbetween}
\usetikzlibrary{arrows,math}
\usepackage{tikz-cd}
\usepackage{tikz-3dplot}
\usetikzlibrary{arrows.meta,bending}
\usepackage{tikzsymbols}
\usepackage{tikzpeople}
\usetikzlibrary{calc}
\usetikzlibrary{chains,positioning,shapes.symbols,fadings,shadows,backgrounds}
\usetikzlibrary{decorations.pathmorphing, decorations.pathreplacing}
\usetikzlibrary{shapes.callouts}
\usetikzlibrary{shapes.arrows,shadings}
\usetikzlibrary{decorations.text}
\usepackage{algorithm,algorithmic}
%\KOMAoptions{optionenliste}
%\KOMAoptions{Option}{Werteliste}
\usepackage{listings}
\usepackage{inconsolata}
\lstset{%
	numbers=left,
	numberstyle=\tiny,
	basicstyle=\ttfamily\fontfamily{courier}\footnotesize,
}


\renewcommand{\arraystretch}{1.1}
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}
\setlength{\textheight}{250mm}
\setlength{\textwidth}{175mm}
\setlength{\hoffset}{-25mm}
\setlength{\voffset}{-15mm}
\allsectionsfont{\centering \normalfont\scshape}


\numberwithin{equation}{section} 
\numberwithin{figure}{section}
\numberwithin{table}{section} 


\newcommand{\ProjectTopic}{Question Answering vs. LLMs}
\newcommand{\ProjectCat}{Open-ended}
\setlength\parindent{0pt}

\fancypagestyle{plain}
{%
	\renewcommand{\headrulewidth}{0pt}%
	\renewcommand{\footrulewidth}{0.5pt}
	\fancyhf{}%
	\fancyfoot[R]{\emph{\footnotesize Page \thepage\ of \pageref{LastPage}}}%
	\fancyfoot[L]{\emph{\footnotesize \ProjectTopic}}%
}
\pagestyle{plain}

\newcommand{\question}[3]{
	\hrule
	\hrule
	\vspace{3pt}
	Question #1: #2 \hfill #3 Points
	\vspace{3pt}
	\hrule
	\hrule
	\vspace{7pt}
}

\newcommand{\code}[1]{\colorbox{gray!20}{\texttt{#1}}}
\newcommand{\textbox}[2]{
	\begin{center}
		\fbox{
			\begin{minipage}{ {#1} em}
				{#2}
			\end{minipage}
		}
	\end{center} 
}
\begin{document}
	
	\titlehead
	{
		\horrule{.5pt}\\
		University of Toronto\\%
		Department of Electrical and Computer Engineering\\%
		ECE1508: \textbf{Applied Deep Learning}
		\hfill
		A. Bereyhi - Fall 2025
		\vspace{-1ex}\\
		\horrule{.5pt}\\
	}
	\subject{}
\title{Project Proposal: Question Answering --- Task-Specific Models vs. LLMs}
	\subtitle{\normalfont \textit{Course Project}\vspace*{-2.5cm}}
	\date{}
	\maketitle
	
	\textbox{43}{\textbf{Code of Honor.} 
		All external resources used in the project, including research papers, open-source repositories, datasets, and any content or code generated using AI tools, e.g., ChatGPT, GitHub Copilot, Claude, Gemini, must be \textit{clearly cited} in the final submission. The final report must also include \textit{a clear breakdown of individual group member contributions.} Any lack of transparency in the use of external resources or in reporting group contributions will be considered academic dishonesty and will significantly impact the final evaluation.
	}
	
\begin{table}[H]
\begin{tabular}{l l}
\hline
\textbf{Topic} & Question Answering --- Task-Specific Models vs. LLMs \\
\textbf{Dataset} & Recipe-MPR multi-perspective recipe QA \\
\hline
\end{tabular}
\end{table}

\paragraph*{Background}
Large language models (LLMs) perform strongly on open-domain question answering, yet their general-purpose nature can miss task-specific nuances. In specialized domains, fine-tuning a focused model often yields gains in efficiency, interpretability, and reliability. The Recipe-MPR dataset, containing 500 user queries with five answer variations apiece, offers a benchmark for multi-perspective responses in the recipe domain and enables a grounded comparison between specialized and general-purpose approaches.

\paragraph*{Objective} 
Fine-tune a task-specific transformer model on Recipe-MPR to surpass the 65\% baseline accuracy while benchmarking performance, robustness, and efficiency against prompted LLM outputs.

\paragraph*{Motivation}
By contrasting a domain-adapted model with a general-purpose LLM, we aim to surface the trade-offs between specialization and broad capability. Understanding when a dedicated model outperforms or complements a large foundation model can inform deployment decisions in domains demanding efficiency, transparency, or domain fidelity.

\paragraph*{Requirements} The final submission should address the following requirements while the details can be freely decided by the group members.
\begin{enumerate}
\item \textbf{Model Training:} Fine-tune a pretrained transformer (e.g., BERT, RoBERTa, DistilBERT) on Recipe-MPR to capture recipe-domain subtleties.
\item \textbf{Evaluation:} Report accuracy and F1-score on a held-out test split to measure task-specific model performance.
\item \textbf{Comparison:} Prompt a state-of-the-art LLM with identical queries, score its responses using the same metrics, and compare with the fine-tuned model.
\item \textbf{Analysis:} Provide qualitative and quantitative analyses to highlight scenarios where the specialized model excels or complements the LLM baseline.
\end{enumerate}

\paragraph*{Milestones}
The following milestones are to be accomplished through semester.
\begin{enumerate}
\item \textbf{Weeks 1--2:} Conduct literature review on recipe QA, finalize dataset handling, and prepare the development environment.
\item \textbf{Weeks 3--4:} Fine-tune the selected transformer model variants on Recipe-MPR.
\item \textbf{Week 5:} Evaluate the task-specific model and benchmark against LLM-generated answers.
\item \textbf{Week 6:} Perform comparative analysis and draft key findings.
\item \textbf{Final Week:} Complete the written report and prepare the project submission materials.
\end{enumerate}

\paragraph*{Expected Outcomes}
We anticipate the fine-tuned model achieving accuracy comparable to or exceeding that of prompted LLMs within the recipe domain. The project should demonstrate the efficiency, domain adaptability, and interpretability gains of specialized models while clarifying the circumstances in which reliance on general-purpose LLMs remains advantageous.


	
\paragraph*{Submission Guidelines} The main body of work is submitted through Git. In addition, each group submits a final paper and gives a presentation. In this respect, please follow these steps.
\begin{itemize}
	\item Each group must maintain a Git repository, e.g., GitHub or GitLab, for the project. By the time of final submission, the repository should have
	\begin{itemize}
		\item Well-documented codebase
		\item Clear \texttt{README.md} with setup and usage instructions
		\item A \texttt{requirements.txt} file listing all required packages or an \texttt{environment.yaml} file with a reproducible environment setup
		\item Demo script or notebook showing sample input-output
		\item \textit{If applicable,} a \texttt{/doc} folder with extended documentation
	\end{itemize}
	\item A final report (maximum \textit{5 pages}) must be submitted in a PDF format. The report should be written in the provided formal style, including an abstract, introduction, method, experiments, results, and conclusion.\\
	\textbf{Important:} Submissions that do not use template are considered \textit{incomplete.}
	\item A 5-minute presentation (maximum \textit{5 slides including the title slide}) is given on the internal seminar on Week 15, i.e., \textit{Dec 8 to Dec 12,} by the group. For presentation, any template can be used.
\end{itemize}

	
	\paragraph*{Final Notes} While planning for the milestones please consider the following points.
	\begin{enumerate}
		\item You are encouraged to explore innovative approaches to conditioning or generation as long as the core objectives are met.
		\item While computational resources are limited, carefully chosen datasets and training setups can make even diffusion models feasible. Trade-offs, e.g., resolution, training steps, are expected and should be justified.
		\item Teams are expected to manage their computing needs and are advised to perform early tests to estimate runtime and training feasibility. As graduate students, team members can use facilities provided by the university, e.g., ECE Facility. Teams are expected to inform themselves about the limitations of the available computing resources and design the model accordingly.
	\end{enumerate}
	
	\bibliographystyle{plain}
	\bibliography{ref.bib}
	
\end{document}
